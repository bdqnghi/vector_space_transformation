org.apache.lucene.analysis.sinks java.io.IOException import java.io.StringReader import java.util.Locale import org.apache.lucene.analysis.Analyzer import org.apache.lucene.analysis.BaseTokenStreamTestCase import org.apache.lucene.analysis.CachingTokenFilter import org.apache.lucene.analysis.MockAnalyzer import org.apache.lucene.analysis.MockTokenizer import org.apache.lucene.analysis.TokenFilter import org.apache.lucene.analysis.TokenStream import org.apache.lucene.analysis.core.LowerCaseFilter import org.apache.lucene.analysis.standard.StandardFilter import org.apache.lucene.analysis.standard.StandardTokenizer import org.apache.lucene.analysis.tokenattributes.CharTermAttribute import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute import org.apache.lucene.analysis.util.FilteringTokenFilter import org.apache.lucene.document.Document import org.apache.lucene.document.Field import org.apache.lucene.document.FieldType import org.apache.lucene.document.TextField import org.apache.lucene.index.DirectoryReader import org.apache.lucene.index.IndexReader import org.apache.lucene.index.IndexWriter import org.apache.lucene.index.PostingsEnum import org.apache.lucene.index.Terms import org.apache.lucene.index.TermsEnum import org.apache.lucene.search.DocIdSetIterator import org.apache.lucene.store.Directory import org.apache.lucene.util.English import class org.apache.lucene.analysis.sinks.TestTeeSinkTokenFilter super super extends decl String decl String StringBuilder StringBuilder public public throws = new = new = new for = < ++ call java.lang.StringBuilder.append(boolean) call java.lang.StringBuilder.append(boolean) call java.lang.StringBuilder.append(boolean) call java.lang.StringBuilder.append(boolean) call java.lang.StringBuilder.append(boolean) = new for = < ++ call java.lang.StringBuilder.append(boolean) call java.lang.StringBuilder.append(boolean) call java.lang.StringBuilder.append(boolean) call java.lang.StringBuilder.append(boolean) call java.lang.StringBuilder.append(boolean) Field Field Terms FieldType TermsEnum Document TeeSinkTokenFilter Analyzer IndexReader TokenStream IndexWriter PostingsEnum TokenStream Directory public public throws decl_stmt org.apache.lucene.store.Directory = decl_stmt org.apache.lucene.analysis.Analyzer = new decl_stmt org.apache.lucene.index.IndexWriter = new decl_stmt org.apache.lucene.document.Document = new decl_stmt org.apache.lucene.analysis.TokenStream = call org.apache.lucene.analysis.Analyzer.tokenStream(String,String) call org.apache.lucene.analysis.Analyzer.tokenStream(String,String) call org.apache.lucene.analysis.Analyzer.tokenStream(String,String) call org.apache.lucene.analysis.Analyzer.tokenStream(String,String) call org.apache.lucene.analysis.Analyzer.tokenStream(String,String) decl_stmt org.apache.lucene.analysis.sinks.TeeSinkTokenFilter = new decl_stmt org.apache.lucene.analysis.TokenStream = call org.apache.lucene.analysis.sinks.TeeSinkTokenFilter.newSinkTokenStream() call org.apache.lucene.analysis.sinks.TeeSinkTokenFilter.newSinkTokenStream() call org.apache.lucene.analysis.sinks.TeeSinkTokenFilter.newSinkTokenStream() call org.apache.lucene.analysis.sinks.TeeSinkTokenFilter.newSinkTokenStream() call org.apache.lucene.analysis.sinks.TeeSinkTokenFilter.newSinkTokenStream() decl_stmt org.apache.solr.schema.FieldType = new call org.apache.solr.schema.FieldType.setStoreTermVectors(boolean) call org.apache.solr.schema.FieldType.setStoreTermVectors(boolean) call org.apache.solr.schema.FieldType.setStoreTermVectors(boolean) call org.apache.solr.schema.FieldType.setStoreTermVectors(boolean) call org.apache.solr.schema.FieldType.setStoreTermVectors(boolean) call org.apache.solr.schema.FieldType.setStoreTermVectorOffsets(boolean) call org.apache.solr.schema.FieldType.setStoreTermVectorOffsets(boolean) call org.apache.solr.schema.FieldType.setStoreTermVectorOffsets(boolean) call org.apache.solr.schema.FieldType.setStoreTermVectorOffsets(boolean) call org.apache.solr.schema.FieldType.setStoreTermVectorOffsets(boolean) call org.apache.solr.schema.FieldType.setStoreTermVectorPositions(boolean) call org.apache.solr.schema.FieldType.setStoreTermVectorPositions(boolean) call org.apache.solr.schema.FieldType.setStoreTermVectorPositions(boolean) call org.apache.solr.schema.FieldType.setStoreTermVectorPositions(boolean) call org.apache.solr.schema.FieldType.setStoreTermVectorPositions(boolean) decl_stmt org.apache.solr.handler.dataimport.config.Field = new decl_stmt org.apache.solr.handler.dataimport.config.Field = new call org.apache.lucene.document.Document.add(IndexableField) call org.apache.lucene.document.Document.add(IndexableField) call org.apache.lucene.document.Document.add(IndexableField) call org.apache.lucene.document.Document.add(IndexableField) call org.apache.lucene.document.Document.add(IndexableField) call org.apache.lucene.document.Document.add(IndexableField) call org.apache.lucene.document.Document.add(IndexableField) call org.apache.lucene.document.Document.add(IndexableField) call org.apache.lucene.document.Document.add(IndexableField) call org.apache.lucene.document.Document.add(IndexableField) call org.apache.lucene.index.IndexWriter.addDocument(Iterable) call org.apache.lucene.index.IndexWriter.addDocument(Iterable) call org.apache.lucene.index.IndexWriter.addDocument(Iterable) call org.apache.lucene.index.IndexWriter.addDocument(Iterable) call org.apache.lucene.index.IndexWriter.addDocument(Iterable) call org.apache.lucene.index.IndexWriter.close() call org.apache.lucene.index.IndexWriter.close() call org.apache.lucene.index.IndexWriter.close() call org.apache.lucene.index.IndexWriter.close() call org.apache.lucene.index.IndexWriter.close() decl_stmt org.apache.lucene.index.IndexReader = decl_stmt org.apache.lucene.index.Terms = call IndexReader.getTermVectors() call IndexReader.getTermVectors() call IndexReader.getTermVectors() call IndexReader.getTermVectors() call IndexReader.getTermVectors() call Terms.size() call Terms.size() call Terms.size() call Terms.size() call Terms.size() decl_stmt org.apache.lucene.index.TermsEnum = call Terms.iterator() call Terms.iterator() call Terms.iterator() call Terms.iterator() call Terms.iterator() call TermsEnum.next() call TermsEnum.next() call TermsEnum.next() call TermsEnum.next() call TermsEnum.next() call org.apache.lucene.index.TermsEnum.totalTermFreq() call org.apache.lucene.index.TermsEnum.totalTermFreq() call org.apache.lucene.index.TermsEnum.totalTermFreq() call org.apache.lucene.index.TermsEnum.totalTermFreq() call org.apache.lucene.index.TermsEnum.totalTermFreq() decl_stmt org.apache.lucene.index.PostingsEnum = call org.apache.lucene.index.TermsEnum.postings(PostingsEnum) call org.apache.lucene.index.TermsEnum.postings(PostingsEnum) call org.apache.lucene.index.TermsEnum.postings(PostingsEnum) call org.apache.lucene.index.TermsEnum.postings(PostingsEnum) call org.apache.lucene.index.TermsEnum.postings(PostingsEnum) call PostingsEnum.nextDoc() call PostingsEnum.nextDoc() call PostingsEnum.nextDoc() call PostingsEnum.nextDoc() call PostingsEnum.nextDoc() != call PostingsEnum.freq() call PostingsEnum.freq() call PostingsEnum.freq() call PostingsEnum.freq() call PostingsEnum.freq() call PostingsEnum.nextPosition() call PostingsEnum.nextPosition() call PostingsEnum.nextPosition() call PostingsEnum.nextPosition() call PostingsEnum.nextPosition() call PostingsEnum.startOffset() call PostingsEnum.startOffset() call PostingsEnum.startOffset() call PostingsEnum.startOffset() call PostingsEnum.startOffset() call PostingsEnum.endOffset() call PostingsEnum.endOffset() call PostingsEnum.endOffset() call PostingsEnum.endOffset() call PostingsEnum.endOffset() call PostingsEnum.nextPosition() call PostingsEnum.nextPosition() call PostingsEnum.nextPosition() call PostingsEnum.nextPosition() call PostingsEnum.nextPosition() call PostingsEnum.startOffset() call PostingsEnum.startOffset() call PostingsEnum.startOffset() call PostingsEnum.startOffset() call PostingsEnum.startOffset() call PostingsEnum.endOffset() call PostingsEnum.endOffset() call PostingsEnum.endOffset() call PostingsEnum.endOffset() call PostingsEnum.endOffset() call PostingsEnum.nextDoc() call PostingsEnum.nextDoc() call PostingsEnum.nextDoc() call PostingsEnum.nextDoc() call PostingsEnum.nextDoc() call org.apache.lucene.index.IndexReader.close() call org.apache.lucene.index.IndexReader.close() call org.apache.lucene.index.IndexReader.close() call org.apache.lucene.index.IndexReader.close() call org.apache.lucene.index.IndexReader.close() call Directory.close() call Directory.close() call Directory.close() call Directory.close() call Directory.close() call org.apache.lucene.analysis.Analyzer.close() call org.apache.lucene.analysis.Analyzer.close() call org.apache.lucene.analysis.Analyzer.close() call org.apache.lucene.analysis.Analyzer.close() call org.apache.lucene.analysis.Analyzer.close() TeeSinkTokenFilter TokenStream public public throws decl_stmt org.apache.lucene.analysis.sinks.TeeSinkTokenFilter final final = new call java.lang.StringBuilder.toString() call java.lang.StringBuilder.toString() call java.lang.StringBuilder.toString() call java.lang.StringBuilder.toString() call java.lang.StringBuilder.toString() decl_stmt org.apache.lucene.analysis.TokenStream final final = call org.apache.lucene.analysis.sinks.TeeSinkTokenFilter.newSinkTokenStream() call org.apache.lucene.analysis.sinks.TeeSinkTokenFilter.newSinkTokenStream() call org.apache.lucene.analysis.sinks.TeeSinkTokenFilter.newSinkTokenStream() call org.apache.lucene.analysis.sinks.TeeSinkTokenFilter.newSinkTokenStream() call org.apache.lucene.analysis.sinks.TeeSinkTokenFilter.newSinkTokenStream() call TeeSinkTokenFilter.addAttribute() call TeeSinkTokenFilter.addAttribute() call TeeSinkTokenFilter.addAttribute() call TeeSinkTokenFilter.addAttribute() call TeeSinkTokenFilter.addAttribute() call TokenStream.addAttribute() call TokenStream.addAttribute() call TokenStream.addAttribute() call TokenStream.addAttribute() call TokenStream.addAttribute() MockTokenizer decl String TokenStream TokenStream TeeSinkTokenFilter TokenStream TeeSinkTokenFilter public public throws decl_stmt org.apache.lucene.analysis.sinks.TeeSinkTokenFilter final final = new call java.lang.StringBuilder.toString() call java.lang.StringBuilder.toString() call java.lang.StringBuilder.toString() call java.lang.StringBuilder.toString() call java.lang.StringBuilder.toString() decl_stmt org.apache.lucene.analysis.TokenStream final final = new call TeeSinkTokenFilter.addAttribute() call TeeSinkTokenFilter.addAttribute() call TeeSinkTokenFilter.addAttribute() call TeeSinkTokenFilter.addAttribute() call TeeSinkTokenFilter.addAttribute() decl_stmt org.apache.lucene.analysis.MockTokenizer = new call TeeSinkTokenFilter.getAttributeFactory() call TeeSinkTokenFilter.getAttributeFactory() call TeeSinkTokenFilter.getAttributeFactory() call TeeSinkTokenFilter.getAttributeFactory() call TeeSinkTokenFilter.getAttributeFactory() call MockTokenizer.setReader() call MockTokenizer.setReader() call MockTokenizer.setReader() call MockTokenizer.setReader() call MockTokenizer.setReader() new call java.lang.StringBuilder.toString() call java.lang.StringBuilder.toString() call java.lang.StringBuilder.toString() call java.lang.StringBuilder.toString() call java.lang.StringBuilder.toString() decl_stmt org.apache.lucene.analysis.sinks.TeeSinkTokenFilter final final = new decl_stmt org.apache.lucene.analysis.TokenStream final final = decl_stmt org.apache.lucene.analysis.TokenStream = new decl_stmt java.lang.String = new for = < ++ = StandardTokenizer private private decl_stmt org.apache.lucene.analysis.standard.StandardTokenizer = new call StandardTokenizer.setReader() call StandardTokenizer.setReader() call StandardTokenizer.setReader() call StandardTokenizer.setReader() call StandardTokenizer.setReader() new return CharTermAttribute long int TokenStream long StringBuilder int PositionIncrementAttribute CharTermAttribute TeeSinkTokenFilter decl int TokenStream decl int public public throws decl_stmt int = decl_stmt int = for = < ++ decl_stmt java.lang.StringBuilder = new + + for = < ++ call java.lang.StringBuilder.append(boolean) call java.lang.StringBuilder.append(boolean) call java.lang.StringBuilder.append(boolean) call java.lang.StringBuilder.append(boolean) call java.lang.StringBuilder.append(boolean) decl_stmt org.apache.lucene.analysis.sinks.TeeSinkTokenFilter = new new decl_stmt org.apache.lucene.analysis.TokenStream = new call org.apache.lucene.analysis.sinks.TeeSinkTokenFilter.newSinkTokenStream() call org.apache.lucene.analysis.sinks.TeeSinkTokenFilter.newSinkTokenStream() call org.apache.lucene.analysis.sinks.TeeSinkTokenFilter.newSinkTokenStream() call org.apache.lucene.analysis.sinks.TeeSinkTokenFilter.newSinkTokenStream() call org.apache.lucene.analysis.sinks.TeeSinkTokenFilter.newSinkTokenStream() call TeeSinkTokenFilter.consumeAllTokens() call TeeSinkTokenFilter.consumeAllTokens() call TeeSinkTokenFilter.consumeAllTokens() call TeeSinkTokenFilter.consumeAllTokens() call TeeSinkTokenFilter.consumeAllTokens() decl_stmt org.apache.lucene.analysis.TokenStream = new new decl_stmt org.apache.lucene.analysis.tokenattributes.CharTermAttribute = call TokenStream.addAttribute() call TokenStream.addAttribute() call TokenStream.addAttribute() call TokenStream.addAttribute() call TokenStream.addAttribute() decl_stmt org.apache.lucene.analysis.tokenattributes.CharTermAttribute = call TokenStream.addAttribute() call TokenStream.addAttribute() call TokenStream.addAttribute() call TokenStream.addAttribute() call TokenStream.addAttribute() for = call TokenStream.incrementToken() call TokenStream.incrementToken() call TokenStream.incrementToken() call TokenStream.incrementToken() call TokenStream.incrementToken() ++ call TokenStream.incrementToken() call TokenStream.incrementToken() call TokenStream.incrementToken() call TokenStream.incrementToken() call TokenStream.incrementToken() + + + + call CharTermAttribute.equals() call CharTermAttribute.equals() call CharTermAttribute.equals() call CharTermAttribute.equals() call CharTermAttribute.equals() == for = < ++ decl_stmt int = decl_stmt long = for = < ++ = new decl_stmt org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute = call TokenStream.getAttribute() call TokenStream.getAttribute() call TokenStream.getAttribute() call TokenStream.getAttribute() call TokenStream.getAttribute() while call TokenStream.incrementToken() call TokenStream.incrementToken() call TokenStream.incrementToken() call TokenStream.incrementToken() call TokenStream.incrementToken() += call PositionIncrementAttribute.getPositionIncrement() call PositionIncrementAttribute.getPositionIncrement() call PositionIncrementAttribute.getPositionIncrement() call PositionIncrementAttribute.getPositionIncrement() call PositionIncrementAttribute.getPositionIncrement() = new new = call TokenStream.getAttribute() call TokenStream.getAttribute() call TokenStream.getAttribute() call TokenStream.getAttribute() call TokenStream.getAttribute() while call TokenStream.incrementToken() call TokenStream.incrementToken() call TokenStream.incrementToken() call TokenStream.incrementToken() call TokenStream.incrementToken() += call PositionIncrementAttribute.getPositionIncrement() call PositionIncrementAttribute.getPositionIncrement() call PositionIncrementAttribute.getPositionIncrement() call PositionIncrementAttribute.getPositionIncrement() call PositionIncrementAttribute.getPositionIncrement() decl_stmt long = + + + - + decl_stmt int = = for = < ++ = new new = new call org.apache.lucene.analysis.sinks.TeeSinkTokenFilter.newSinkTokenStream() call org.apache.lucene.analysis.sinks.TeeSinkTokenFilter.newSinkTokenStream() call org.apache.lucene.analysis.sinks.TeeSinkTokenFilter.newSinkTokenStream() call org.apache.lucene.analysis.sinks.TeeSinkTokenFilter.newSinkTokenStream() call org.apache.lucene.analysis.sinks.TeeSinkTokenFilter.newSinkTokenStream() decl_stmt org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute = call TeeSinkTokenFilter.getAttribute() call TeeSinkTokenFilter.getAttribute() call TeeSinkTokenFilter.getAttribute() call TeeSinkTokenFilter.getAttribute() call TeeSinkTokenFilter.getAttribute() while call org.apache.lucene.analysis.sinks.TeeSinkTokenFilter.incrementToken() call org.apache.lucene.analysis.sinks.TeeSinkTokenFilter.incrementToken() call org.apache.lucene.analysis.sinks.TeeSinkTokenFilter.incrementToken() call org.apache.lucene.analysis.sinks.TeeSinkTokenFilter.incrementToken() call org.apache.lucene.analysis.sinks.TeeSinkTokenFilter.incrementToken() += call PositionIncrementAttribute.getPositionIncrement() call PositionIncrementAttribute.getPositionIncrement() call PositionIncrementAttribute.getPositionIncrement() call PositionIncrementAttribute.getPositionIncrement() call PositionIncrementAttribute.getPositionIncrement() = call TokenStream.getAttribute() call TokenStream.getAttribute() call TokenStream.getAttribute() call TokenStream.getAttribute() call TokenStream.getAttribute() while call TokenStream.incrementToken() call TokenStream.incrementToken() call TokenStream.incrementToken() call TokenStream.incrementToken() call TokenStream.incrementToken() += call PositionIncrementAttribute.getPositionIncrement() call PositionIncrementAttribute.getPositionIncrement() call PositionIncrementAttribute.getPositionIncrement() call PositionIncrementAttribute.getPositionIncrement() call PositionIncrementAttribute.getPositionIncrement() = + + + - + + + == + + boolean public public throws decl_stmt boolean for = && != = ++ ++ return boolean protected protected throws decl_stmt boolean = == ++ return