org.apache.lucene.analysis.core java.io.IOException import java.io.StringReader import java.util.HashMap import java.util.Map import org.apache.lucene.analysis.BaseTokenStreamTestCase import org.apache.lucene.analysis.Tokenizer import org.apache.lucene.util.AttributeFactory import class org.apache.lucene.analysis.core.TestUnicodeWhitespaceTokenizer super super extends UnicodeWhitespaceTokenizer StringReader public public throws decl_stmt java.io.StringReader = new decl_stmt org.apache.lucene.analysis.core.UnicodeWhitespaceTokenizer = new call UnicodeWhitespaceTokenizer.setReader() call UnicodeWhitespaceTokenizer.setReader() call UnicodeWhitespaceTokenizer.setReader() call UnicodeWhitespaceTokenizer.setReader() call UnicodeWhitespaceTokenizer.setReader() new UnicodeWhitespaceTokenizer StringReader public public throws decl_stmt java.io.StringReader = new decl_stmt org.apache.lucene.analysis.core.UnicodeWhitespaceTokenizer = new call UnicodeWhitespaceTokenizer.setReader() call UnicodeWhitespaceTokenizer.setReader() call UnicodeWhitespaceTokenizer.setReader() call UnicodeWhitespaceTokenizer.setReader() call UnicodeWhitespaceTokenizer.setReader() new AttributeFactory decl Map WhitespaceTokenizerFactory Tokenizer public public decl_stmt java.util.Map < = new <> call decl Map.put() call decl Map.put() call decl Map.put() call decl Map.put() call decl Map.put() decl_stmt org.apache.lucene.analysis.core.WhitespaceTokenizerFactory = new decl_stmt org.apache.lucene.util.AttributeFactory = decl_stmt org.apache.lucene.analysis.Tokenizer = call WhitespaceTokenizerFactory.create() call WhitespaceTokenizerFactory.create() call WhitespaceTokenizerFactory.create() call WhitespaceTokenizerFactory.create() call WhitespaceTokenizerFactory.create() call Tokenizer.getClass() call Tokenizer.getClass() call Tokenizer.getClass() call Tokenizer.getClass() call Tokenizer.getClass()