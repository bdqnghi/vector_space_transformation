org.apache.lucene.analysis.compound java.io.IOException import java.io.Reader import java.io.StringReader import java.util.Arrays import org.apache.lucene.analysis.Analyzer import org.apache.lucene.analysis.BaseTokenStreamTestCase import org.apache.lucene.analysis.MockTokenizer import org.apache.lucene.analysis.TokenFilter import org.apache.lucene.analysis.TokenStream import org.apache.lucene.analysis.Tokenizer import org.apache.lucene.analysis.charfilter.MappingCharFilter import org.apache.lucene.analysis.charfilter.NormalizeCharMap import org.apache.lucene.analysis.compound.hyphenation.HyphenationTree import org.apache.lucene.analysis.core.KeywordTokenizer import org.apache.lucene.analysis.util.CharArraySet import org.apache.lucene.analysis.tokenattributes.CharTermAttribute import org.apache.lucene.util.Attribute import org.apache.lucene.util.AttributeImpl import org.apache.lucene.util.AttributeReflector import org.xml.sax.InputSource import class org.apache.lucene.analysis.compound.TestCompoundWordTokenFilter super super extends private static private static return new HyphenationCompoundWordTokenFilter InputSource CharArraySet HyphenationTree public public throws decl_stmt org.apache.lucene.analysis.util.CharArraySet = decl_stmt InputSource = new decl_stmt org.apache.lucene.analysis.compound.hyphenation.HyphenationTree = decl_stmt org.apache.lucene.analysis.compound.HyphenationCompoundWordTokenFilter = new new new HyphenationCompoundWordTokenFilter InputSource CharArraySet HyphenationTree public public throws decl_stmt org.apache.lucene.analysis.util.CharArraySet = decl_stmt InputSource = new decl_stmt org.apache.lucene.analysis.compound.hyphenation.HyphenationTree = decl_stmt org.apache.lucene.analysis.compound.HyphenationCompoundWordTokenFilter = new new new HyphenationCompoundWordTokenFilter InputSource HyphenationTree public public throws decl_stmt InputSource = new decl_stmt org.apache.lucene.analysis.compound.hyphenation.HyphenationTree = decl_stmt org.apache.lucene.analysis.compound.HyphenationCompoundWordTokenFilter = new new = new new = new new DictionaryCompoundWordTokenFilter CharArraySet public public throws decl_stmt org.apache.lucene.analysis.util.CharArraySet = decl_stmt org.apache.lucene.analysis.compound.DictionaryCompoundWordTokenFilter = new new new new new DictionaryCompoundWordTokenFilter CharArraySet public public throws decl_stmt org.apache.lucene.analysis.util.CharArraySet = decl_stmt org.apache.lucene.analysis.compound.DictionaryCompoundWordTokenFilter = new new new new new DictionaryCompoundWordTokenFilter CharArraySet Tokenizer public public throws decl_stmt org.apache.lucene.analysis.util.CharArraySet = decl_stmt org.apache.lucene.analysis.Tokenizer = new call org.apache.lucene.analysis.Tokenizer.setReader(Reader) call org.apache.lucene.analysis.Tokenizer.setReader(Reader) call org.apache.lucene.analysis.Tokenizer.setReader(Reader) call org.apache.lucene.analysis.Tokenizer.setReader(Reader) call org.apache.lucene.analysis.Tokenizer.setReader(Reader) new decl_stmt org.apache.lucene.analysis.compound.DictionaryCompoundWordTokenFilter = new new new new new DictionaryCompoundWordTokenFilter CharArraySet Tokenizer public public throws decl_stmt org.apache.lucene.analysis.util.CharArraySet = decl_stmt org.apache.lucene.analysis.Tokenizer = new call org.apache.lucene.analysis.Tokenizer.setReader(Reader) call org.apache.lucene.analysis.Tokenizer.setReader(Reader) call org.apache.lucene.analysis.Tokenizer.setReader(Reader) call org.apache.lucene.analysis.Tokenizer.setReader(Reader) call org.apache.lucene.analysis.Tokenizer.setReader(Reader) new decl_stmt org.apache.lucene.analysis.compound.DictionaryCompoundWordTokenFilter = new new new new new DictionaryCompoundWordTokenFilter CharTermAttribute CharArraySet MockTokenizer public public throws decl_stmt org.apache.lucene.analysis.util.CharArraySet = decl_stmt org.apache.lucene.analysis.MockTokenizer = new call org.apache.lucene.analysis.MockTokenizer.setEnableChecks(boolean) call org.apache.lucene.analysis.MockTokenizer.setEnableChecks(boolean) call org.apache.lucene.analysis.MockTokenizer.setEnableChecks(boolean) call org.apache.lucene.analysis.MockTokenizer.setEnableChecks(boolean) call org.apache.lucene.analysis.MockTokenizer.setEnableChecks(boolean) call MockTokenizer.setReader() call MockTokenizer.setReader() call MockTokenizer.setReader() call MockTokenizer.setReader() call MockTokenizer.setReader() new decl_stmt org.apache.lucene.analysis.compound.DictionaryCompoundWordTokenFilter = new decl_stmt org.apache.lucene.analysis.tokenattributes.CharTermAttribute = call DictionaryCompoundWordTokenFilter.getAttribute() call DictionaryCompoundWordTokenFilter.getAttribute() call DictionaryCompoundWordTokenFilter.getAttribute() call DictionaryCompoundWordTokenFilter.getAttribute() call DictionaryCompoundWordTokenFilter.getAttribute() call DictionaryCompoundWordTokenFilter.reset() call DictionaryCompoundWordTokenFilter.reset() call DictionaryCompoundWordTokenFilter.reset() call DictionaryCompoundWordTokenFilter.reset() call DictionaryCompoundWordTokenFilter.reset() call DictionaryCompoundWordTokenFilter.incrementToken() call DictionaryCompoundWordTokenFilter.incrementToken() call DictionaryCompoundWordTokenFilter.incrementToken() call DictionaryCompoundWordTokenFilter.incrementToken() call DictionaryCompoundWordTokenFilter.incrementToken() call CharTermAttribute.toString() call CharTermAttribute.toString() call CharTermAttribute.toString() call CharTermAttribute.toString() call CharTermAttribute.toString() call DictionaryCompoundWordTokenFilter.incrementToken() call DictionaryCompoundWordTokenFilter.incrementToken() call DictionaryCompoundWordTokenFilter.incrementToken() call DictionaryCompoundWordTokenFilter.incrementToken() call DictionaryCompoundWordTokenFilter.incrementToken() call CharTermAttribute.toString() call CharTermAttribute.toString() call CharTermAttribute.toString() call CharTermAttribute.toString() call CharTermAttribute.toString() call DictionaryCompoundWordTokenFilter.end() call DictionaryCompoundWordTokenFilter.end() call DictionaryCompoundWordTokenFilter.end() call DictionaryCompoundWordTokenFilter.end() call DictionaryCompoundWordTokenFilter.end() call DictionaryCompoundWordTokenFilter.close() call DictionaryCompoundWordTokenFilter.close() call DictionaryCompoundWordTokenFilter.close() call DictionaryCompoundWordTokenFilter.close() call DictionaryCompoundWordTokenFilter.close() call MockTokenizer.setReader() call MockTokenizer.setReader() call MockTokenizer.setReader() call MockTokenizer.setReader() call MockTokenizer.setReader() new call DictionaryCompoundWordTokenFilter.reset() call DictionaryCompoundWordTokenFilter.reset() call DictionaryCompoundWordTokenFilter.reset() call DictionaryCompoundWordTokenFilter.reset() call DictionaryCompoundWordTokenFilter.reset() call DictionaryCompoundWordTokenFilter.incrementToken() call DictionaryCompoundWordTokenFilter.incrementToken() call DictionaryCompoundWordTokenFilter.incrementToken() call DictionaryCompoundWordTokenFilter.incrementToken() call DictionaryCompoundWordTokenFilter.incrementToken() call CharTermAttribute.toString() call CharTermAttribute.toString() call CharTermAttribute.toString() call CharTermAttribute.toString() call CharTermAttribute.toString() MockRetainAttribute CharArraySet TokenStream Tokenizer public public throws decl_stmt org.apache.lucene.analysis.util.CharArraySet = decl_stmt org.apache.lucene.analysis.Tokenizer = new call org.apache.lucene.analysis.Tokenizer.setReader(Reader) call org.apache.lucene.analysis.Tokenizer.setReader(Reader) call org.apache.lucene.analysis.Tokenizer.setReader(Reader) call org.apache.lucene.analysis.Tokenizer.setReader(Reader) call org.apache.lucene.analysis.Tokenizer.setReader(Reader) new decl_stmt org.apache.lucene.analysis.TokenStream = new = new decl_stmt org.apache.lucene.analysis.compound.MockRetainAttribute = call TokenStream.addAttribute() call TokenStream.addAttribute() call TokenStream.addAttribute() call TokenStream.addAttribute() call TokenStream.addAttribute() call org.apache.lucene.analysis.TokenStream.reset() call org.apache.lucene.analysis.TokenStream.reset() call org.apache.lucene.analysis.TokenStream.reset() call org.apache.lucene.analysis.TokenStream.reset() call org.apache.lucene.analysis.TokenStream.reset() while call TokenStream.incrementToken() call TokenStream.incrementToken() call TokenStream.incrementToken() call TokenStream.incrementToken() call TokenStream.incrementToken() call org.apache.lucene.analysis.compound.MockRetainAttribute.getRetain() call org.apache.lucene.analysis.compound.MockRetainAttribute.getRetain() call org.apache.lucene.analysis.compound.MockRetainAttribute.getRetain() call org.apache.lucene.analysis.compound.MockRetainAttribute.getRetain() call org.apache.lucene.analysis.compound.MockRetainAttribute.getRetain() public public = public public return public public = MockRetainAttribute public public decl_stmt org.apache.lucene.analysis.compound.MockRetainAttribute = call MockRetainAttribute.setRetain() call MockRetainAttribute.setRetain() call MockRetainAttribute.setRetain() call MockRetainAttribute.setRetain() call MockRetainAttribute.setRetain() public public public public throws if return else return Analyzer decl NormalizeCharMap NormalizeCharMap decl Builder Tokenizer CharArraySet public public throws decl_stmt org.apache.lucene.analysis.util.CharArraySet final final = decl_stmt org.apache.lucene.util.fst.Builder final final final final final = new call decl NormalizeCharMap.add() call decl NormalizeCharMap.add() call decl NormalizeCharMap.add() call decl NormalizeCharMap.add() call decl NormalizeCharMap.add() decl_stmt org.apache.lucene.analysis.charfilter.NormalizeCharMap final final = call decl NormalizeCharMap.build() call decl NormalizeCharMap.build() call decl NormalizeCharMap.build() call decl NormalizeCharMap.build() call decl NormalizeCharMap.build() decl_stmt org.apache.lucene.analysis.Analyzer = new protected protected decl_stmt org.apache.lucene.analysis.Tokenizer = new decl_stmt org.apache.lucene.analysis.TokenFilter = new return new protected protected return new new new new call NormalizeCharMap.close() call NormalizeCharMap.close() call NormalizeCharMap.close() call NormalizeCharMap.close() call NormalizeCharMap.close() TokenFilter Tokenizer protected protected decl_stmt org.apache.lucene.analysis.Tokenizer = new decl_stmt org.apache.lucene.analysis.TokenFilter = new return new protected protected return new Analyzer HyphenationTree Analyzer Tokenizer InputSource TokenFilter CharArraySet public public throws decl_stmt org.apache.lucene.analysis.util.CharArraySet final final = decl_stmt org.apache.lucene.analysis.Analyzer = new protected protected decl_stmt org.apache.lucene.analysis.Tokenizer = new return new new * call org.apache.lucene.analysis.Analyzer.close() call org.apache.lucene.analysis.Analyzer.close() call org.apache.lucene.analysis.Analyzer.close() call org.apache.lucene.analysis.Analyzer.close() call org.apache.lucene.analysis.Analyzer.close() decl_stmt InputSource = new decl_stmt org.apache.lucene.analysis.compound.hyphenation.HyphenationTree final final = decl_stmt org.apache.lucene.analysis.Analyzer = new protected protected decl_stmt org.apache.lucene.analysis.Tokenizer = new decl_stmt org.apache.lucene.analysis.TokenFilter = new return new * call org.apache.lucene.analysis.Analyzer.close() call org.apache.lucene.analysis.Analyzer.close() call org.apache.lucene.analysis.Analyzer.close() call org.apache.lucene.analysis.Analyzer.close() call org.apache.lucene.analysis.Analyzer.close() Tokenizer protected protected decl_stmt org.apache.lucene.analysis.Tokenizer = new return new new TokenFilter Tokenizer protected protected decl_stmt org.apache.lucene.analysis.Tokenizer = new decl_stmt org.apache.lucene.analysis.TokenFilter = new return new Analyzer HyphenationTree Analyzer Tokenizer InputSource TokenFilter CharArraySet public public throws decl_stmt org.apache.lucene.analysis.util.CharArraySet final final = decl_stmt org.apache.lucene.analysis.Analyzer = new protected protected decl_stmt org.apache.lucene.analysis.Tokenizer = new return new new call org.apache.lucene.analysis.Analyzer.close() call org.apache.lucene.analysis.Analyzer.close() call org.apache.lucene.analysis.Analyzer.close() call org.apache.lucene.analysis.Analyzer.close() call org.apache.lucene.analysis.Analyzer.close() decl_stmt InputSource = new decl_stmt org.apache.lucene.analysis.compound.hyphenation.HyphenationTree final final = decl_stmt org.apache.lucene.analysis.Analyzer = new protected protected decl_stmt org.apache.lucene.analysis.Tokenizer = new decl_stmt org.apache.lucene.analysis.TokenFilter = new return new call org.apache.lucene.analysis.Analyzer.close() call org.apache.lucene.analysis.Analyzer.close() call org.apache.lucene.analysis.Analyzer.close() call org.apache.lucene.analysis.Analyzer.close() call org.apache.lucene.analysis.Analyzer.close() Tokenizer protected protected decl_stmt org.apache.lucene.analysis.Tokenizer = new return new new TokenFilter Tokenizer protected protected decl_stmt org.apache.lucene.analysis.Tokenizer = new decl_stmt org.apache.lucene.analysis.TokenFilter = new return new