org.apache.lucene.analysis.ngram java.io.IOException import java.io.StringReader import java.util.Random import org.apache.lucene.analysis.Analyzer import org.apache.lucene.analysis.BaseTokenStreamTestCase import org.apache.lucene.analysis.MockTokenizer import org.apache.lucene.analysis.TokenFilter import org.apache.lucene.analysis.TokenStream import org.apache.lucene.analysis.Tokenizer import org.apache.lucene.analysis.core.KeywordTokenizer import org.apache.lucene.analysis.core.LetterTokenizer import org.apache.lucene.analysis.core.WhitespaceTokenizer import org.apache.lucene.analysis.shingle.ShingleFilter import org.apache.lucene.analysis.tokenattributes.CharTermAttribute import org.apache.lucene.analysis.tokenattributes.OffsetAttribute import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute import org.apache.lucene.util.TestUtil import class org.apache.lucene.analysis.ngram.EdgeNGramTokenFilterTest super super extends TokenStream public public throws = public public throws new public public throws new public public throws new - EdgeNGramTokenFilter public public throws decl_stmt org.apache.lucene.analysis.ngram.EdgeNGramTokenFilter = new new new new EdgeNGramTokenFilter public public throws decl_stmt org.apache.lucene.analysis.ngram.EdgeNGramTokenFilter = new new new new EdgeNGramTokenFilter public public throws decl_stmt org.apache.lucene.analysis.ngram.EdgeNGramTokenFilter = new new new new TokenStream EdgeNGramTokenFilter public public throws decl_stmt org.apache.lucene.analysis.TokenStream = decl_stmt org.apache.lucene.analysis.ngram.EdgeNGramTokenFilter = new new new new new public final public final throws if call TokenStream.incrementToken() call TokenStream.incrementToken() call TokenStream.incrementToken() call TokenStream.incrementToken() call TokenStream.incrementToken() if else = return else return public public throws = EdgeNGramTokenFilter TokenStream public public throws decl_stmt org.apache.lucene.analysis.TokenStream = = new decl_stmt org.apache.lucene.analysis.ngram.EdgeNGramTokenFilter = new new new new new EdgeNGramTokenFilter public public throws = decl_stmt org.apache.lucene.analysis.ngram.EdgeNGramTokenFilter = new new new new EdgeNGramTokenFilter WhitespaceTokenizer public public throws decl_stmt org.apache.lucene.analysis.core.WhitespaceTokenizer = new call WhitespaceTokenizer.setReader() call WhitespaceTokenizer.setReader() call WhitespaceTokenizer.setReader() call WhitespaceTokenizer.setReader() call WhitespaceTokenizer.setReader() new decl_stmt org.apache.lucene.analysis.ngram.EdgeNGramTokenFilter = new new new new call WhitespaceTokenizer.setReader() call WhitespaceTokenizer.setReader() call WhitespaceTokenizer.setReader() call WhitespaceTokenizer.setReader() call WhitespaceTokenizer.setReader() new new new new Analyzer int Tokenizer int public public throws for = < ++ decl_stmt int final final = decl_stmt int final final = decl_stmt org.apache.lucene.analysis.Analyzer = new protected protected decl_stmt org.apache.lucene.analysis.Tokenizer = new return new new * call org.apache.lucene.analysis.Analyzer.close() call org.apache.lucene.analysis.Analyzer.close() call org.apache.lucene.analysis.Analyzer.close() call org.apache.lucene.analysis.Analyzer.close() call org.apache.lucene.analysis.Analyzer.close() Tokenizer protected protected decl_stmt org.apache.lucene.analysis.Tokenizer = new return new new Analyzer Random Tokenizer public public throws decl_stmt java.util.Random = decl_stmt org.apache.lucene.analysis.Analyzer = new protected protected decl_stmt org.apache.lucene.analysis.Tokenizer = new return new new call java.util.Random.nextBoolean() call java.util.Random.nextBoolean() call java.util.Random.nextBoolean() call java.util.Random.nextBoolean() call java.util.Random.nextBoolean() call org.apache.lucene.analysis.Analyzer.close() call org.apache.lucene.analysis.Analyzer.close() call org.apache.lucene.analysis.Analyzer.close() call org.apache.lucene.analysis.Analyzer.close() call org.apache.lucene.analysis.Analyzer.close() Tokenizer protected protected decl_stmt org.apache.lucene.analysis.Tokenizer = new return new new TokenStream public public throws decl_stmt org.apache.lucene.analysis.TokenStream = new new = new = new new new new new new int int String CharTermAttribute TokenStream int int OffsetAttribute public public throws decl_stmt java.lang.String final final = decl_stmt int final final = call java.lang.String.codePointCount(int,int) call java.lang.String.codePointCount(int,int) call java.lang.String.codePointCount(int,int) call java.lang.String.codePointCount(int,int) call java.lang.String.codePointCount(int,int) call java.lang.String.length() call java.lang.String.length() call java.lang.String.length() call java.lang.String.length() call java.lang.String.length() decl_stmt int final final = decl_stmt int final final = decl_stmt org.apache.lucene.analysis.TokenStream = new new = new decl_stmt org.apache.lucene.analysis.tokenattributes.CharTermAttribute final final = call TokenStream.addAttribute() call TokenStream.addAttribute() call TokenStream.addAttribute() call TokenStream.addAttribute() call TokenStream.addAttribute() decl_stmt org.apache.lucene.analysis.tokenattributes.OffsetAttribute final final = call TokenStream.addAttribute() call TokenStream.addAttribute() call TokenStream.addAttribute() call TokenStream.addAttribute() call TokenStream.addAttribute() call org.apache.lucene.analysis.TokenStream.reset() call org.apache.lucene.analysis.TokenStream.reset() call org.apache.lucene.analysis.TokenStream.reset() call org.apache.lucene.analysis.TokenStream.reset() call org.apache.lucene.analysis.TokenStream.reset() for = <= ++ call TokenStream.incrementToken() call TokenStream.incrementToken() call TokenStream.incrementToken() call TokenStream.incrementToken() call TokenStream.incrementToken() call OffsetAttribute.startOffset() call OffsetAttribute.startOffset() call OffsetAttribute.startOffset() call OffsetAttribute.startOffset() call OffsetAttribute.startOffset() call java.lang.String.length() call java.lang.String.length() call java.lang.String.length() call java.lang.String.length() call java.lang.String.length() call org.apache.lucene.analysis.tokenattributes.OffsetAttribute.endOffset() call org.apache.lucene.analysis.tokenattributes.OffsetAttribute.endOffset() call org.apache.lucene.analysis.tokenattributes.OffsetAttribute.endOffset() call org.apache.lucene.analysis.tokenattributes.OffsetAttribute.endOffset() call org.apache.lucene.analysis.tokenattributes.OffsetAttribute.endOffset() decl_stmt int final final = call java.lang.String.substring(int) call java.lang.String.substring(int) call java.lang.String.substring(int) call java.lang.String.substring(int) call java.lang.String.substring(int) call CharTermAttribute.toString() call CharTermAttribute.toString() call CharTermAttribute.toString() call CharTermAttribute.toString() call CharTermAttribute.toString() call TokenStream.incrementToken() call TokenStream.incrementToken() call TokenStream.incrementToken() call TokenStream.incrementToken() call TokenStream.incrementToken()