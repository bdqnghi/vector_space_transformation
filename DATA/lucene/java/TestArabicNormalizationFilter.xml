org.apache.lucene.analysis.ar java.io.IOException import java.io.Reader import java.io.StringReader import org.apache.lucene.analysis.Analyzer import org.apache.lucene.analysis.BaseTokenStreamTestCase import org.apache.lucene.analysis.MockTokenizer import org.apache.lucene.analysis.Tokenizer import org.apache.lucene.analysis.core.KeywordTokenizer import class org.apache.lucene.analysis.ar.TestArabicNormalizationFilter super super extends public public throws public public throws public public throws public public throws public public throws public public throws public public throws public public throws public public throws public public throws public public throws public public throws public public throws public public throws ArabicNormalizationFilter MockTokenizer private private final final final final throws decl_stmt org.apache.lucene.analysis.MockTokenizer = new call MockTokenizer.setReader() call MockTokenizer.setReader() call MockTokenizer.setReader() call MockTokenizer.setReader() call MockTokenizer.setReader() new decl_stmt org.apache.lucene.analysis.ar.ArabicNormalizationFilter = new new Analyzer Tokenizer public public throws decl_stmt org.apache.lucene.analysis.Analyzer = new protected protected decl_stmt org.apache.lucene.analysis.Tokenizer = new return new new call org.apache.lucene.analysis.Analyzer.close() call org.apache.lucene.analysis.Analyzer.close() call org.apache.lucene.analysis.Analyzer.close() call org.apache.lucene.analysis.Analyzer.close() call org.apache.lucene.analysis.Analyzer.close() Tokenizer protected protected decl_stmt org.apache.lucene.analysis.Tokenizer = new return new new