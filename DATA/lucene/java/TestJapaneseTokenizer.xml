org.apache.lucene.analysis.ja java.io.IOException import java.io.InputStream import java.io.InputStreamReader import java.io.LineNumberReader import java.io.Reader import java.io.StringReader import java.nio.charset.StandardCharsets import java.util.ArrayList import java.util.Random import org.apache.lucene.analysis.Analyzer import org.apache.lucene.analysis.BaseTokenStreamTestCase import org.apache.lucene.analysis.MockGraphTokenFilter import org.apache.lucene.analysis.TokenStream import org.apache.lucene.analysis.Tokenizer import org.apache.lucene.analysis.ja.JapaneseTokenizer.Mode import org.apache.lucene.analysis.ja.dict.ConnectionCosts import org.apache.lucene.analysis.ja.dict.UserDictionary import org.apache.lucene.analysis.ja.tokenattributes.* import org.apache.lucene.analysis.tokenattributes.CharTermAttribute import org.apache.lucene.util.IOUtils import org.apache.lucene.util.TestUtil import org.apache.lucene.util.UnicodeUtil import class org.apache.lucene.analysis.ja.TestJapaneseTokenizer super super extends Analyzer InputStream Reader public static public static decl_stmt java.io.InputStream = if == throw new try try decl_stmt java.io.Reader = new return finally call java.io.InputStream.close() call java.io.InputStream.close() call java.io.InputStream.close() call java.io.InputStream.close() call java.io.InputStream.close() catch throw new private private return new private private final final return new protected protected return new protected protected return new Tokenizer public public throws = new protected protected decl_stmt org.apache.lucene.analysis.Tokenizer = new return new = new protected protected decl_stmt org.apache.lucene.analysis.Tokenizer = new return new = new protected protected decl_stmt org.apache.lucene.analysis.ja.JapaneseTokenizer = new call Tokenizer.setNBestCost() call Tokenizer.setNBestCost() call Tokenizer.setNBestCost() call Tokenizer.setNBestCost() call Tokenizer.setNBestCost() return new = new protected protected decl_stmt org.apache.lucene.analysis.Tokenizer = new return new = new protected protected decl_stmt org.apache.lucene.analysis.Tokenizer = new return new Tokenizer protected protected decl_stmt org.apache.lucene.analysis.Tokenizer = new return new Tokenizer protected protected decl_stmt org.apache.lucene.analysis.Tokenizer = new return new JapaneseTokenizer protected protected decl_stmt org.apache.lucene.analysis.ja.JapaneseTokenizer = new call org.apache.lucene.analysis.ja.JapaneseTokenizer.setNBestCost(int) call org.apache.lucene.analysis.ja.JapaneseTokenizer.setNBestCost(int) call org.apache.lucene.analysis.ja.JapaneseTokenizer.setNBestCost(int) call org.apache.lucene.analysis.ja.JapaneseTokenizer.setNBestCost(int) call org.apache.lucene.analysis.ja.JapaneseTokenizer.setNBestCost(int) return new Tokenizer protected protected decl_stmt org.apache.lucene.analysis.Tokenizer = new return new Tokenizer protected protected decl_stmt org.apache.lucene.analysis.Tokenizer = new return new public public throws public public throws new Analyzer JapaneseTokenizer public public throws decl_stmt org.apache.lucene.analysis.ja.JapaneseTokenizer = decl_stmt org.apache.lucene.analysis.Analyzer = call org.apache.lucene.analysis.ja.JapaneseTokenizer.setNBestCost(int) call org.apache.lucene.analysis.ja.JapaneseTokenizer.setNBestCost(int) call org.apache.lucene.analysis.ja.JapaneseTokenizer.setNBestCost(int) call org.apache.lucene.analysis.ja.JapaneseTokenizer.setNBestCost(int) call org.apache.lucene.analysis.ja.JapaneseTokenizer.setNBestCost(int) new call org.apache.lucene.analysis.ja.JapaneseTokenizer.setNBestCost(int) call org.apache.lucene.analysis.ja.JapaneseTokenizer.setNBestCost(int) call org.apache.lucene.analysis.ja.JapaneseTokenizer.setNBestCost(int) call org.apache.lucene.analysis.ja.JapaneseTokenizer.setNBestCost(int) call org.apache.lucene.analysis.ja.JapaneseTokenizer.setNBestCost(int) new call org.apache.lucene.analysis.ja.JapaneseTokenizer.setNBestCost(int) call org.apache.lucene.analysis.ja.JapaneseTokenizer.setNBestCost(int) call org.apache.lucene.analysis.ja.JapaneseTokenizer.setNBestCost(int) call org.apache.lucene.analysis.ja.JapaneseTokenizer.setNBestCost(int) call org.apache.lucene.analysis.ja.JapaneseTokenizer.setNBestCost(int) new call org.apache.lucene.analysis.ja.JapaneseTokenizer.setNBestCost(int) call org.apache.lucene.analysis.ja.JapaneseTokenizer.setNBestCost(int) call org.apache.lucene.analysis.ja.JapaneseTokenizer.setNBestCost(int) call org.apache.lucene.analysis.ja.JapaneseTokenizer.setNBestCost(int) call org.apache.lucene.analysis.ja.JapaneseTokenizer.setNBestCost(int) new call org.apache.lucene.analysis.ja.JapaneseTokenizer.setNBestCost(int) call org.apache.lucene.analysis.ja.JapaneseTokenizer.setNBestCost(int) call org.apache.lucene.analysis.ja.JapaneseTokenizer.setNBestCost(int) call org.apache.lucene.analysis.ja.JapaneseTokenizer.setNBestCost(int) call org.apache.lucene.analysis.ja.JapaneseTokenizer.setNBestCost(int) new call org.apache.lucene.analysis.ja.JapaneseTokenizer.setNBestCost(int) call org.apache.lucene.analysis.ja.JapaneseTokenizer.setNBestCost(int) call org.apache.lucene.analysis.ja.JapaneseTokenizer.setNBestCost(int) call org.apache.lucene.analysis.ja.JapaneseTokenizer.setNBestCost(int) call org.apache.lucene.analysis.ja.JapaneseTokenizer.setNBestCost(int) new call org.apache.lucene.analysis.ja.JapaneseTokenizer.setNBestCost(int) call org.apache.lucene.analysis.ja.JapaneseTokenizer.setNBestCost(int) call org.apache.lucene.analysis.ja.JapaneseTokenizer.setNBestCost(int) call org.apache.lucene.analysis.ja.JapaneseTokenizer.setNBestCost(int) call org.apache.lucene.analysis.ja.JapaneseTokenizer.setNBestCost(int) new call org.apache.lucene.analysis.ja.JapaneseTokenizer.setNBestCost(int) call org.apache.lucene.analysis.ja.JapaneseTokenizer.setNBestCost(int) call org.apache.lucene.analysis.ja.JapaneseTokenizer.setNBestCost(int) call org.apache.lucene.analysis.ja.JapaneseTokenizer.setNBestCost(int) call org.apache.lucene.analysis.ja.JapaneseTokenizer.setNBestCost(int) new Analyzer JapaneseTokenizer public public throws decl_stmt org.apache.lucene.analysis.ja.JapaneseTokenizer = decl_stmt org.apache.lucene.analysis.Analyzer = call org.apache.lucene.analysis.ja.JapaneseTokenizer.setNBestCost(int) call org.apache.lucene.analysis.ja.JapaneseTokenizer.setNBestCost(int) call org.apache.lucene.analysis.ja.JapaneseTokenizer.setNBestCost(int) call org.apache.lucene.analysis.ja.JapaneseTokenizer.setNBestCost(int) call org.apache.lucene.analysis.ja.JapaneseTokenizer.setNBestCost(int) new call org.apache.lucene.analysis.ja.JapaneseTokenizer.setNBestCost(int) call org.apache.lucene.analysis.ja.JapaneseTokenizer.setNBestCost(int) call org.apache.lucene.analysis.ja.JapaneseTokenizer.setNBestCost(int) call org.apache.lucene.analysis.ja.JapaneseTokenizer.setNBestCost(int) call org.apache.lucene.analysis.ja.JapaneseTokenizer.setNBestCost(int) new CharTermAttribute decl ArrayList TokenStream private < private < throws decl_stmt java.util.ArrayList < = new <> decl_stmt org.apache.lucene.analysis.TokenStream = decl_stmt org.apache.lucene.analysis.tokenattributes.CharTermAttribute = call TokenStream.getAttribute() call TokenStream.getAttribute() call TokenStream.getAttribute() call TokenStream.getAttribute() call TokenStream.getAttribute() call org.apache.lucene.analysis.TokenStream.reset() call org.apache.lucene.analysis.TokenStream.reset() call org.apache.lucene.analysis.TokenStream.reset() call org.apache.lucene.analysis.TokenStream.reset() call org.apache.lucene.analysis.TokenStream.reset() while call TokenStream.incrementToken() call TokenStream.incrementToken() call TokenStream.incrementToken() call TokenStream.incrementToken() call TokenStream.incrementToken() call decl ArrayList.add() call decl ArrayList.add() call decl ArrayList.add() call decl ArrayList.add() call decl ArrayList.add() call CharTermAttribute.toString() call CharTermAttribute.toString() call CharTermAttribute.toString() call CharTermAttribute.toString() call CharTermAttribute.toString() call org.apache.lucene.analysis.TokenStream.end() call org.apache.lucene.analysis.TokenStream.end() call org.apache.lucene.analysis.TokenStream.end() call org.apache.lucene.analysis.TokenStream.end() call org.apache.lucene.analysis.TokenStream.end() call org.apache.lucene.analysis.TokenStream.close() call org.apache.lucene.analysis.TokenStream.close() call org.apache.lucene.analysis.TokenStream.close() call org.apache.lucene.analysis.TokenStream.close() call org.apache.lucene.analysis.TokenStream.close() return private private throws return != - Analyzer JapaneseTokenizer public public throws decl_stmt org.apache.lucene.analysis.ja.JapaneseTokenizer = decl_stmt org.apache.lucene.analysis.Analyzer = call org.apache.lucene.analysis.ja.JapaneseTokenizer.setNBestCost(int) call org.apache.lucene.analysis.ja.JapaneseTokenizer.setNBestCost(int) call org.apache.lucene.analysis.ja.JapaneseTokenizer.setNBestCost(int) call org.apache.lucene.analysis.ja.JapaneseTokenizer.setNBestCost(int) call org.apache.lucene.analysis.ja.JapaneseTokenizer.setNBestCost(int) <= call org.apache.lucene.analysis.ja.JapaneseTokenizer.calcNBestCost(String) call org.apache.lucene.analysis.ja.JapaneseTokenizer.calcNBestCost(String) call org.apache.lucene.analysis.ja.JapaneseTokenizer.calcNBestCost(String) call org.apache.lucene.analysis.ja.JapaneseTokenizer.calcNBestCost(String) call org.apache.lucene.analysis.ja.JapaneseTokenizer.calcNBestCost(String) call org.apache.lucene.analysis.ja.JapaneseTokenizer.setNBestCost(int) call org.apache.lucene.analysis.ja.JapaneseTokenizer.setNBestCost(int) call org.apache.lucene.analysis.ja.JapaneseTokenizer.setNBestCost(int) call org.apache.lucene.analysis.ja.JapaneseTokenizer.setNBestCost(int) call org.apache.lucene.analysis.ja.JapaneseTokenizer.setNBestCost(int) call org.apache.lucene.analysis.ja.JapaneseTokenizer.calcNBestCost(String) call org.apache.lucene.analysis.ja.JapaneseTokenizer.calcNBestCost(String) call org.apache.lucene.analysis.ja.JapaneseTokenizer.calcNBestCost(String) call org.apache.lucene.analysis.ja.JapaneseTokenizer.calcNBestCost(String) call org.apache.lucene.analysis.ja.JapaneseTokenizer.calcNBestCost(String) <= call org.apache.lucene.analysis.ja.JapaneseTokenizer.calcNBestCost(String) call org.apache.lucene.analysis.ja.JapaneseTokenizer.calcNBestCost(String) call org.apache.lucene.analysis.ja.JapaneseTokenizer.calcNBestCost(String) call org.apache.lucene.analysis.ja.JapaneseTokenizer.calcNBestCost(String) call org.apache.lucene.analysis.ja.JapaneseTokenizer.calcNBestCost(String) call org.apache.lucene.analysis.ja.JapaneseTokenizer.setNBestCost(int) call org.apache.lucene.analysis.ja.JapaneseTokenizer.setNBestCost(int) call org.apache.lucene.analysis.ja.JapaneseTokenizer.setNBestCost(int) call org.apache.lucene.analysis.ja.JapaneseTokenizer.setNBestCost(int) call org.apache.lucene.analysis.ja.JapaneseTokenizer.setNBestCost(int) call org.apache.lucene.analysis.ja.JapaneseTokenizer.calcNBestCost(String) call org.apache.lucene.analysis.ja.JapaneseTokenizer.calcNBestCost(String) call org.apache.lucene.analysis.ja.JapaneseTokenizer.calcNBestCost(String) call org.apache.lucene.analysis.ja.JapaneseTokenizer.calcNBestCost(String) call org.apache.lucene.analysis.ja.JapaneseTokenizer.calcNBestCost(String) public public throws + new new new public public throws new new new public public throws new new new public public throws new new new public public throws try = call org.apache.lucene.analysis.Analyzer.tokenStream(String,String) call org.apache.lucene.analysis.Analyzer.tokenStream(String,String) call org.apache.lucene.analysis.Analyzer.tokenStream(String,String) call org.apache.lucene.analysis.Analyzer.tokenStream(String,String) call org.apache.lucene.analysis.Analyzer.tokenStream(String,String) while public public throws new new new public public throws * * * Random public public throws decl_stmt java.util.Random = * * * TokenStream Random Tokenizer Analyzer public public throws decl_stmt java.util.Random = decl_stmt org.apache.lucene.analysis.Analyzer = new protected protected decl_stmt org.apache.lucene.analysis.Tokenizer = new decl_stmt org.apache.lucene.analysis.TokenStream = new return new * call org.apache.lucene.analysis.Analyzer.close() call org.apache.lucene.analysis.Analyzer.close() call org.apache.lucene.analysis.Analyzer.close() call org.apache.lucene.analysis.Analyzer.close() call org.apache.lucene.analysis.Analyzer.close() TokenStream Tokenizer protected protected decl_stmt org.apache.lucene.analysis.Tokenizer = new decl_stmt org.apache.lucene.analysis.TokenStream = new return new String public public throws for = < ++ decl_stmt java.lang.String = try = call org.apache.lucene.analysis.Analyzer.tokenStream(String,String) call org.apache.lucene.analysis.Analyzer.tokenStream(String,String) call org.apache.lucene.analysis.Analyzer.tokenStream(String,String) call org.apache.lucene.analysis.Analyzer.tokenStream(String,String) call org.apache.lucene.analysis.Analyzer.tokenStream(String,String) while public public throws new int String CharTermAttribute public public throws decl_stmt int = for = < ++ if + decl_stmt java.lang.String = try = call org.apache.lucene.analysis.Analyzer.tokenStream(String,String) call org.apache.lucene.analysis.Analyzer.tokenStream(String,String) call org.apache.lucene.analysis.Analyzer.tokenStream(String,String) call org.apache.lucene.analysis.Analyzer.tokenStream(String,String) call org.apache.lucene.analysis.Analyzer.tokenStream(String,String) decl_stmt org.apache.lucene.analysis.tokenattributes.CharTermAttribute = while public public throws try = public public throws try = public public throws new new new new new new new new public public throws call org.apache.lucene.analysis.Analyzer.tokenStream(String,String) call org.apache.lucene.analysis.Analyzer.tokenStream(String,String) call org.apache.lucene.analysis.Analyzer.tokenStream(String,String) call org.apache.lucene.analysis.Analyzer.tokenStream(String,String) call org.apache.lucene.analysis.Analyzer.tokenStream(String,String) new new new new public public throws call org.apache.lucene.analysis.Analyzer.tokenStream(String,String) call org.apache.lucene.analysis.Analyzer.tokenStream(String,String) call org.apache.lucene.analysis.Analyzer.tokenStream(String,String) call org.apache.lucene.analysis.Analyzer.tokenStream(String,String) call org.apache.lucene.analysis.Analyzer.tokenStream(String,String) new new new new public public throws call org.apache.lucene.analysis.Analyzer.tokenStream(String,String) call org.apache.lucene.analysis.Analyzer.tokenStream(String,String) call org.apache.lucene.analysis.Analyzer.tokenStream(String,String) call org.apache.lucene.analysis.Analyzer.tokenStream(String,String) call org.apache.lucene.analysis.Analyzer.tokenStream(String,String) new new new new String decl String public public throws decl_stmt java.lang.String = decl_stmt java.lang.String = GraphvizFormatter String JapaneseTokenizer Analyzer decl String public public throws decl_stmt org.apache.lucene.analysis.ja.GraphvizFormatter final final = new decl_stmt org.apache.lucene.analysis.Analyzer final final = new protected protected decl_stmt org.apache.lucene.analysis.ja.JapaneseTokenizer = new call org.apache.lucene.analysis.ja.JapaneseTokenizer.setGraphvizFormatter(GraphvizFormatter) call org.apache.lucene.analysis.ja.JapaneseTokenizer.setGraphvizFormatter(GraphvizFormatter) call org.apache.lucene.analysis.ja.JapaneseTokenizer.setGraphvizFormatter(GraphvizFormatter) call org.apache.lucene.analysis.ja.JapaneseTokenizer.setGraphvizFormatter(GraphvizFormatter) call org.apache.lucene.analysis.ja.JapaneseTokenizer.setGraphvizFormatter(GraphvizFormatter) return new decl_stmt java.lang.String = decl_stmt java.lang.String = call org.apache.lucene.analysis.ja.GraphvizFormatter.finish() call org.apache.lucene.analysis.ja.GraphvizFormatter.finish() call org.apache.lucene.analysis.ja.GraphvizFormatter.finish() call org.apache.lucene.analysis.ja.GraphvizFormatter.finish() call org.apache.lucene.analysis.ja.GraphvizFormatter.finish() != - call org.apache.lucene.analysis.Analyzer.close() call org.apache.lucene.analysis.Analyzer.close() call org.apache.lucene.analysis.Analyzer.close() call org.apache.lucene.analysis.Analyzer.close() call org.apache.lucene.analysis.Analyzer.close() JapaneseTokenizer protected protected decl_stmt org.apache.lucene.analysis.ja.JapaneseTokenizer = new call org.apache.lucene.analysis.ja.JapaneseTokenizer.setGraphvizFormatter(GraphvizFormatter) call org.apache.lucene.analysis.ja.JapaneseTokenizer.setGraphvizFormatter(GraphvizFormatter) call org.apache.lucene.analysis.ja.JapaneseTokenizer.setGraphvizFormatter(GraphvizFormatter) call org.apache.lucene.analysis.ja.JapaneseTokenizer.setGraphvizFormatter(GraphvizFormatter) call org.apache.lucene.analysis.ja.JapaneseTokenizer.setGraphvizFormatter(GraphvizFormatter) return new ReadingAttribute private private throws try = call org.apache.lucene.analysis.Analyzer.tokenStream(String,String) call org.apache.lucene.analysis.Analyzer.tokenStream(String,String) call org.apache.lucene.analysis.Analyzer.tokenStream(String,String) call org.apache.lucene.analysis.Analyzer.tokenStream(String,String) call org.apache.lucene.analysis.Analyzer.tokenStream(String,String) decl_stmt org.apache.lucene.analysis.ja.tokenattributes.ReadingAttribute = for : call org.apache.lucene.analysis.ja.tokenattributes.ReadingAttribute.getReading() call org.apache.lucene.analysis.ja.tokenattributes.ReadingAttribute.getReading() call org.apache.lucene.analysis.ja.tokenattributes.ReadingAttribute.getReading() call org.apache.lucene.analysis.ja.tokenattributes.ReadingAttribute.getReading() call org.apache.lucene.analysis.ja.tokenattributes.ReadingAttribute.getReading() ReadingAttribute private private throws try = call org.apache.lucene.analysis.Analyzer.tokenStream(String,String) call org.apache.lucene.analysis.Analyzer.tokenStream(String,String) call org.apache.lucene.analysis.Analyzer.tokenStream(String,String) call org.apache.lucene.analysis.Analyzer.tokenStream(String,String) call org.apache.lucene.analysis.Analyzer.tokenStream(String,String) decl_stmt org.apache.lucene.analysis.ja.tokenattributes.ReadingAttribute = for : call ReadingAttribute.getPronunciation() call ReadingAttribute.getPronunciation() call ReadingAttribute.getPronunciation() call ReadingAttribute.getPronunciation() call ReadingAttribute.getPronunciation() BaseFormAttribute private private throws try = call org.apache.lucene.analysis.Analyzer.tokenStream(String,String) call org.apache.lucene.analysis.Analyzer.tokenStream(String,String) call org.apache.lucene.analysis.Analyzer.tokenStream(String,String) call org.apache.lucene.analysis.Analyzer.tokenStream(String,String) call org.apache.lucene.analysis.Analyzer.tokenStream(String,String) decl_stmt org.apache.lucene.analysis.ja.tokenattributes.BaseFormAttribute = for : call org.apache.lucene.analysis.ja.tokenattributes.BaseFormAttribute.getBaseForm() call org.apache.lucene.analysis.ja.tokenattributes.BaseFormAttribute.getBaseForm() call org.apache.lucene.analysis.ja.tokenattributes.BaseFormAttribute.getBaseForm() call org.apache.lucene.analysis.ja.tokenattributes.BaseFormAttribute.getBaseForm() call org.apache.lucene.analysis.ja.tokenattributes.BaseFormAttribute.getBaseForm() InflectionAttribute private private throws try = call org.apache.lucene.analysis.Analyzer.tokenStream(String,String) call org.apache.lucene.analysis.Analyzer.tokenStream(String,String) call org.apache.lucene.analysis.Analyzer.tokenStream(String,String) call org.apache.lucene.analysis.Analyzer.tokenStream(String,String) call org.apache.lucene.analysis.Analyzer.tokenStream(String,String) decl_stmt org.apache.lucene.analysis.ja.tokenattributes.InflectionAttribute = for : call org.apache.lucene.analysis.ja.tokenattributes.InflectionAttribute.getInflectionType() call org.apache.lucene.analysis.ja.tokenattributes.InflectionAttribute.getInflectionType() call org.apache.lucene.analysis.ja.tokenattributes.InflectionAttribute.getInflectionType() call org.apache.lucene.analysis.ja.tokenattributes.InflectionAttribute.getInflectionType() call org.apache.lucene.analysis.ja.tokenattributes.InflectionAttribute.getInflectionType() InflectionAttribute private private throws try = call org.apache.lucene.analysis.Analyzer.tokenStream(String,String) call org.apache.lucene.analysis.Analyzer.tokenStream(String,String) call org.apache.lucene.analysis.Analyzer.tokenStream(String,String) call org.apache.lucene.analysis.Analyzer.tokenStream(String,String) call org.apache.lucene.analysis.Analyzer.tokenStream(String,String) decl_stmt org.apache.lucene.analysis.ja.tokenattributes.InflectionAttribute = for : call org.apache.lucene.analysis.ja.tokenattributes.InflectionAttribute.getInflectionForm() call org.apache.lucene.analysis.ja.tokenattributes.InflectionAttribute.getInflectionForm() call org.apache.lucene.analysis.ja.tokenattributes.InflectionAttribute.getInflectionForm() call org.apache.lucene.analysis.ja.tokenattributes.InflectionAttribute.getInflectionForm() call org.apache.lucene.analysis.ja.tokenattributes.InflectionAttribute.getInflectionForm() PartOfSpeechAttribute private private throws try = call org.apache.lucene.analysis.Analyzer.tokenStream(String,String) call org.apache.lucene.analysis.Analyzer.tokenStream(String,String) call org.apache.lucene.analysis.Analyzer.tokenStream(String,String) call org.apache.lucene.analysis.Analyzer.tokenStream(String,String) call org.apache.lucene.analysis.Analyzer.tokenStream(String,String) decl_stmt org.apache.lucene.analysis.ja.tokenattributes.PartOfSpeechAttribute = for : call org.apache.lucene.analysis.ja.tokenattributes.PartOfSpeechAttribute.getPartOfSpeech() call org.apache.lucene.analysis.ja.tokenattributes.PartOfSpeechAttribute.getPartOfSpeech() call org.apache.lucene.analysis.ja.tokenattributes.PartOfSpeechAttribute.getPartOfSpeech() call org.apache.lucene.analysis.ja.tokenattributes.PartOfSpeechAttribute.getPartOfSpeech() call org.apache.lucene.analysis.ja.tokenattributes.PartOfSpeechAttribute.getPartOfSpeech() public public throws public public throws public public throws public public throws public public throws public public throws public public throws public public throws public public throws new public public throws new public public throws public public throws String decl String long LineNumberReader private private throws decl_stmt java.io.LineNumberReader = new new decl_stmt java.lang.String = call java.io.LineNumberReader.readLine() call java.io.LineNumberReader.readLine() call java.io.LineNumberReader.readLine() call java.io.LineNumberReader.readLine() call java.io.LineNumberReader.readLine() call LineNumberReader.close() call LineNumberReader.close() call LineNumberReader.close() call LineNumberReader.close() call LineNumberReader.close() if decl_stmt long = for = < ++ try = call org.apache.lucene.analysis.Analyzer.tokenStream(String,String) call org.apache.lucene.analysis.Analyzer.tokenStream(String,String) call org.apache.lucene.analysis.Analyzer.tokenStream(String,String) call org.apache.lucene.analysis.Analyzer.tokenStream(String,String) call org.apache.lucene.analysis.Analyzer.tokenStream(String,String) while decl_stmt java.lang.String = call java.lang.String.split(String) call java.lang.String.split(String) call java.lang.String.split(String) call java.lang.String.split(String) call java.lang.String.split(String) if + - + + = for = < ++ for : try = call org.apache.lucene.analysis.Analyzer.tokenStream(String,String) call org.apache.lucene.analysis.Analyzer.tokenStream(String,String) call org.apache.lucene.analysis.Analyzer.tokenStream(String,String) call org.apache.lucene.analysis.Analyzer.tokenStream(String,String) call org.apache.lucene.analysis.Analyzer.tokenStream(String,String) while if + - public public throws new new public public throws new new new Analyzer Tokenizer Reader UserDictionary public public throws decl_stmt java.io.Reader = new decl_stmt org.apache.lucene.analysis.ja.dict.UserDictionary = decl_stmt org.apache.lucene.analysis.Analyzer = new protected protected decl_stmt org.apache.lucene.analysis.Tokenizer = new return new new new new call org.apache.lucene.analysis.Analyzer.close() call org.apache.lucene.analysis.Analyzer.close() call org.apache.lucene.analysis.Analyzer.close() call org.apache.lucene.analysis.Analyzer.close() call org.apache.lucene.analysis.Analyzer.close() Tokenizer protected protected decl_stmt org.apache.lucene.analysis.Tokenizer = new return new