org.apache.lucene.analysis.ngram org.apache.lucene.analysis.Analyzer import org.apache.lucene.analysis.MockTokenizer import org.apache.lucene.analysis.TokenFilter import org.apache.lucene.analysis.TokenStream import org.apache.lucene.analysis.BaseTokenStreamTestCase import org.apache.lucene.analysis.Tokenizer import org.apache.lucene.analysis.core.KeywordTokenizer import org.apache.lucene.analysis.core.WhitespaceTokenizer import org.apache.lucene.analysis.miscellaneous.ASCIIFoldingFilter import org.apache.lucene.analysis.tokenattributes.CharTermAttribute import org.apache.lucene.analysis.tokenattributes.OffsetAttribute import org.apache.lucene.util.TestUtil import java.io.IOException import java.io.StringReader import java.util.Random import class org.apache.lucene.analysis.ngram.NGramTokenFilterTest super super extends TokenStream public public throws = public public throws new public public throws new NGramTokenFilter public public throws decl_stmt org.apache.lucene.analysis.ngram.NGramTokenFilter = new new new new new NGramTokenFilter public public throws decl_stmt org.apache.lucene.analysis.ngram.NGramTokenFilter = new new new new new NGramTokenFilter public public throws decl_stmt org.apache.lucene.analysis.ngram.NGramTokenFilter = new new new new new NGramTokenFilter public public throws decl_stmt org.apache.lucene.analysis.ngram.NGramTokenFilter = new new new new new NGramTokenFilter public public throws decl_stmt org.apache.lucene.analysis.ngram.NGramTokenFilter = new new new new NGramTokenFilter public public throws = decl_stmt org.apache.lucene.analysis.ngram.NGramTokenFilter = new new new new new NGramTokenFilter WhitespaceTokenizer public public throws decl_stmt org.apache.lucene.analysis.core.WhitespaceTokenizer = new call WhitespaceTokenizer.setReader() call WhitespaceTokenizer.setReader() call WhitespaceTokenizer.setReader() call WhitespaceTokenizer.setReader() call WhitespaceTokenizer.setReader() new decl_stmt org.apache.lucene.analysis.ngram.NGramTokenFilter = new new new new new call WhitespaceTokenizer.setReader() call WhitespaceTokenizer.setReader() call WhitespaceTokenizer.setReader() call WhitespaceTokenizer.setReader() call WhitespaceTokenizer.setReader() new new new new new TokenFilter Tokenizer Analyzer public public throws decl_stmt org.apache.lucene.analysis.Analyzer = new protected protected decl_stmt org.apache.lucene.analysis.Tokenizer = new decl_stmt org.apache.lucene.analysis.TokenFilter = new = new return new new new new new call org.apache.lucene.analysis.Analyzer.close() call org.apache.lucene.analysis.Analyzer.close() call org.apache.lucene.analysis.Analyzer.close() call org.apache.lucene.analysis.Analyzer.close() call org.apache.lucene.analysis.Analyzer.close() TokenFilter Tokenizer protected protected decl_stmt org.apache.lucene.analysis.Tokenizer = new decl_stmt org.apache.lucene.analysis.TokenFilter = new = new return new Analyzer int Tokenizer int public public throws for = < ++ decl_stmt int final final = decl_stmt int final final = decl_stmt org.apache.lucene.analysis.Analyzer = new protected protected decl_stmt org.apache.lucene.analysis.Tokenizer = new return new new * call org.apache.lucene.analysis.Analyzer.close() call org.apache.lucene.analysis.Analyzer.close() call org.apache.lucene.analysis.Analyzer.close() call org.apache.lucene.analysis.Analyzer.close() call org.apache.lucene.analysis.Analyzer.close() Tokenizer protected protected decl_stmt org.apache.lucene.analysis.Tokenizer = new return new new Analyzer Random Tokenizer public public throws decl_stmt java.util.Random = decl_stmt org.apache.lucene.analysis.Analyzer = new protected protected decl_stmt org.apache.lucene.analysis.Tokenizer = new return new new call java.util.Random.nextBoolean() call java.util.Random.nextBoolean() call java.util.Random.nextBoolean() call java.util.Random.nextBoolean() call java.util.Random.nextBoolean() call org.apache.lucene.analysis.Analyzer.close() call org.apache.lucene.analysis.Analyzer.close() call org.apache.lucene.analysis.Analyzer.close() call org.apache.lucene.analysis.Analyzer.close() call org.apache.lucene.analysis.Analyzer.close() Tokenizer protected protected decl_stmt org.apache.lucene.analysis.Tokenizer = new return new new int int int String CharTermAttribute TokenStream int int OffsetAttribute public public throws decl_stmt java.lang.String final final = decl_stmt int final final = call java.lang.String.codePointCount(int,int) call java.lang.String.codePointCount(int,int) call java.lang.String.codePointCount(int,int) call java.lang.String.codePointCount(int,int) call java.lang.String.codePointCount(int,int) call java.lang.String.length() call java.lang.String.length() call java.lang.String.length() call java.lang.String.length() call java.lang.String.length() decl_stmt int final final = decl_stmt int final final = decl_stmt org.apache.lucene.analysis.TokenStream = new new = new decl_stmt org.apache.lucene.analysis.tokenattributes.CharTermAttribute final final = call TokenStream.addAttribute() call TokenStream.addAttribute() call TokenStream.addAttribute() call TokenStream.addAttribute() call TokenStream.addAttribute() decl_stmt org.apache.lucene.analysis.tokenattributes.OffsetAttribute final final = call TokenStream.addAttribute() call TokenStream.addAttribute() call TokenStream.addAttribute() call TokenStream.addAttribute() call TokenStream.addAttribute() call org.apache.lucene.analysis.TokenStream.reset() call org.apache.lucene.analysis.TokenStream.reset() call org.apache.lucene.analysis.TokenStream.reset() call org.apache.lucene.analysis.TokenStream.reset() call org.apache.lucene.analysis.TokenStream.reset() for = < ++ for = + <= + ++ call TokenStream.incrementToken() call TokenStream.incrementToken() call TokenStream.incrementToken() call TokenStream.incrementToken() call TokenStream.incrementToken() call OffsetAttribute.startOffset() call OffsetAttribute.startOffset() call OffsetAttribute.startOffset() call OffsetAttribute.startOffset() call OffsetAttribute.startOffset() call java.lang.String.length() call java.lang.String.length() call java.lang.String.length() call java.lang.String.length() call java.lang.String.length() call org.apache.lucene.analysis.tokenattributes.OffsetAttribute.endOffset() call org.apache.lucene.analysis.tokenattributes.OffsetAttribute.endOffset() call org.apache.lucene.analysis.tokenattributes.OffsetAttribute.endOffset() call org.apache.lucene.analysis.tokenattributes.OffsetAttribute.endOffset() call org.apache.lucene.analysis.tokenattributes.OffsetAttribute.endOffset() decl_stmt int final final = decl_stmt int final final = call java.lang.String.substring(int) call java.lang.String.substring(int) call java.lang.String.substring(int) call java.lang.String.substring(int) call java.lang.String.substring(int) call CharTermAttribute.toString() call CharTermAttribute.toString() call CharTermAttribute.toString() call CharTermAttribute.toString() call CharTermAttribute.toString() call TokenStream.incrementToken() call TokenStream.incrementToken() call TokenStream.incrementToken() call TokenStream.incrementToken() call TokenStream.incrementToken()