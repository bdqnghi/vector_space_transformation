org.apache.lucene.analysis.fa java.io.IOException import org.apache.lucene.analysis.TokenFilter import org.apache.lucene.analysis.TokenStream import org.apache.lucene.analysis.tokenattributes.CharTermAttribute import class org.apache.lucene.analysis.fa.PersianNormalizationFilter super super extends PersianNormalizer CharTermAttribute int public public throws if decl_stmt int final final = call PersianNormalizer.normalize() call PersianNormalizer.normalize() call PersianNormalizer.normalize() call PersianNormalizer.normalize() call PersianNormalizer.normalize() call org.apache.lucene.analysis.tokenattributes.CharTermAttribute.buffer() call org.apache.lucene.analysis.tokenattributes.CharTermAttribute.buffer() call org.apache.lucene.analysis.tokenattributes.CharTermAttribute.buffer() call org.apache.lucene.analysis.tokenattributes.CharTermAttribute.buffer() call org.apache.lucene.analysis.tokenattributes.CharTermAttribute.buffer() call CharTermAttribute.length() call CharTermAttribute.length() call CharTermAttribute.length() call CharTermAttribute.length() call CharTermAttribute.length() call org.apache.lucene.analysis.tokenattributes.CharTermAttribute.setLength(int) call org.apache.lucene.analysis.tokenattributes.CharTermAttribute.setLength(int) call org.apache.lucene.analysis.tokenattributes.CharTermAttribute.setLength(int) call org.apache.lucene.analysis.tokenattributes.CharTermAttribute.setLength(int) call org.apache.lucene.analysis.tokenattributes.CharTermAttribute.setLength(int) return return