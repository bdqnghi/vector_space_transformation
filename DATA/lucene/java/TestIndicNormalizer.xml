org.apache.lucene.analysis.in java.io.IOException import java.io.StringReader import org.apache.lucene.analysis.Analyzer import org.apache.lucene.analysis.BaseTokenStreamTestCase import org.apache.lucene.analysis.MockTokenizer import org.apache.lucene.analysis.TokenFilter import org.apache.lucene.analysis.Tokenizer import org.apache.lucene.analysis.core.KeywordTokenizer import class org.apache.lucene.analysis.in.TestIndicNormalizer super super extends public public throws TokenFilter Tokenizer private private throws decl_stmt org.apache.lucene.analysis.Tokenizer = new call org.apache.lucene.analysis.Tokenizer.setReader(Reader) call org.apache.lucene.analysis.Tokenizer.setReader(Reader) call org.apache.lucene.analysis.Tokenizer.setReader(Reader) call org.apache.lucene.analysis.Tokenizer.setReader(Reader) call org.apache.lucene.analysis.Tokenizer.setReader(Reader) new decl_stmt org.apache.lucene.analysis.TokenFilter = new new Analyzer Tokenizer public public throws decl_stmt org.apache.lucene.analysis.Analyzer = new protected protected decl_stmt org.apache.lucene.analysis.Tokenizer = new return new new call org.apache.lucene.analysis.Analyzer.close() call org.apache.lucene.analysis.Analyzer.close() call org.apache.lucene.analysis.Analyzer.close() call org.apache.lucene.analysis.Analyzer.close() call org.apache.lucene.analysis.Analyzer.close() Tokenizer protected protected decl_stmt org.apache.lucene.analysis.Tokenizer = new return new new