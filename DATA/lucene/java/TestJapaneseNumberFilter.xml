org.apache.lucene.analysis.ja java.io.IOException import java.io.Reader import java.io.Writer import java.nio.charset.StandardCharsets import java.nio.file.Files import java.nio.file.Path import java.nio.file.Paths import org.apache.lucene.analysis.Analyzer import org.apache.lucene.analysis.BaseTokenStreamTestCase import org.apache.lucene.analysis.TokenStream import org.apache.lucene.analysis.Tokenizer import org.apache.lucene.analysis.miscellaneous.SetKeywordMarkerFilter import org.apache.lucene.analysis.tokenattributes.CharTermAttribute import org.apache.lucene.analysis.util.CharArraySet import org.junit.Ignore import org.junit.Test import class org.apache.lucene.analysis.ja.TestJapaneseNumberFilter super super extends Analyzer Tokenizer public public throws = new protected protected decl_stmt org.apache.lucene.analysis.Tokenizer = new return new new Tokenizer protected protected decl_stmt org.apache.lucene.analysis.Tokenizer = new return new new public public throws call org.apache.lucene.analysis.Analyzer.close() call org.apache.lucene.analysis.Analyzer.close() call org.apache.lucene.analysis.Analyzer.close() call org.apache.lucene.analysis.Analyzer.close() call org.apache.lucene.analysis.Analyzer.close() public public throws new new new new new new new new new public public throws new new new new new new new new new new new new new new new public public throws new new new new new new new public public throws new public public throws new new public public throws new new new new public public throws new public public throws new new new public public throws new new public public throws new new new new CharArraySet Tokenizer Analyzer public public throws new new new new decl_stmt org.apache.lucene.analysis.Analyzer = new protected protected decl_stmt org.apache.lucene.analysis.util.CharArraySet = new call org.apache.lucene.analysis.util.CharArraySet.add(Object) call org.apache.lucene.analysis.util.CharArraySet.add(Object) call org.apache.lucene.analysis.util.CharArraySet.add(Object) call org.apache.lucene.analysis.util.CharArraySet.add(Object) call org.apache.lucene.analysis.util.CharArraySet.add(Object) decl_stmt org.apache.lucene.analysis.Tokenizer = new return new new new new new new new call org.apache.lucene.analysis.Analyzer.close() call org.apache.lucene.analysis.Analyzer.close() call org.apache.lucene.analysis.Analyzer.close() call org.apache.lucene.analysis.Analyzer.close() call org.apache.lucene.analysis.Analyzer.close() CharArraySet Tokenizer protected protected decl_stmt org.apache.lucene.analysis.util.CharArraySet = new call org.apache.lucene.analysis.util.CharArraySet.add(Object) call org.apache.lucene.analysis.util.CharArraySet.add(Object) call org.apache.lucene.analysis.util.CharArraySet.add(Object) call org.apache.lucene.analysis.util.CharArraySet.add(Object) call org.apache.lucene.analysis.util.CharArraySet.add(Object) decl_stmt org.apache.lucene.analysis.Tokenizer = new return new new new public public throws new public public throws new public public throws new public public throws new public public throws new public public throws new new public public throws new public public throws * public public throws * public public throws Path Path Path Tokenizer Analyzer public public throws decl_stmt java.nio.file.Path = decl_stmt java.nio.file.Path = decl_stmt java.nio.file.Path = decl_stmt org.apache.lucene.analysis.Analyzer = new protected protected decl_stmt org.apache.lucene.analysis.Tokenizer = new return new call org.apache.lucene.analysis.Analyzer.close() call org.apache.lucene.analysis.Analyzer.close() call org.apache.lucene.analysis.Analyzer.close() call org.apache.lucene.analysis.Analyzer.close() call org.apache.lucene.analysis.Analyzer.close() Tokenizer protected protected decl_stmt org.apache.lucene.analysis.Tokenizer = new return new CharTermAttribute TokenStream public public throws decl_stmt org.apache.lucene.analysis.TokenStream = call org.apache.lucene.analysis.Analyzer.tokenStream(String,String) call org.apache.lucene.analysis.Analyzer.tokenStream(String,String) call org.apache.lucene.analysis.Analyzer.tokenStream(String,String) call org.apache.lucene.analysis.Analyzer.tokenStream(String,String) call org.apache.lucene.analysis.Analyzer.tokenStream(String,String) call org.apache.lucene.analysis.TokenStream.reset() call org.apache.lucene.analysis.TokenStream.reset() call org.apache.lucene.analysis.TokenStream.reset() call org.apache.lucene.analysis.TokenStream.reset() call org.apache.lucene.analysis.TokenStream.reset() decl_stmt org.apache.lucene.analysis.tokenattributes.CharTermAttribute = call TokenStream.addAttribute() call TokenStream.addAttribute() call TokenStream.addAttribute() call TokenStream.addAttribute() call TokenStream.addAttribute() while call TokenStream.incrementToken() call TokenStream.incrementToken() call TokenStream.incrementToken() call TokenStream.incrementToken() call TokenStream.incrementToken() call CharTermAttribute.toString() call CharTermAttribute.toString() call CharTermAttribute.toString() call CharTermAttribute.toString() call CharTermAttribute.toString()